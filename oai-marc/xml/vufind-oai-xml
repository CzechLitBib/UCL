#!/usr/bin/python3
#
# Update database from OAI-PMH 2.0
#

import argparse,rrdtool,sqlite3,locale,sys,io,re

from pymarc import MARCWriter,marcxml,Field,Record
from datetime import datetime,timedelta
from lxml.etree import tostring
from oaipmh.client import Client
from oaipmh.metadata import MetadataRegistry

OAI_URL='https://aleph.lib.cas.cz/OAI'
OAI_SET='UCLO'
DELETES='deletes.txt'

# DEF -------------------

def valid_date(date):
	try:
		return datetime.strptime(date, '%Y-%m-%d %H:%M:%S')
	except:
		raise argparse.ArgumentTypeError('Invalid date format.')

def MarcXML(xml):
	handler = marcxml.XmlHandler()
	marcxml.parse_xml(io.StringIO(tostring(xml).decode('utf-8')), handler)
	return handler.records[0]

def name_invert(s,ID):
	if len(s.split(',')) == 2:
		return s.split(',')[1].strip() + ' ' + s.split(',')[0].strip() 
	else:
		print(ID, '#Multiple comma.')
	return s

def name_to_upper(s,ID):
	if len(s.split(',')) == 2:
		return s.split(',')[0].strip().upper() + ', ' + s.split(',')[1].strip() 
	else:
		print(ID, '#Multiple comma.')
	return s

def word_to_upper(s):
	word,buff = '',''
	for char in s:
		if not word and re.match('\w', char, re.UNICODE):
			char = char.upper()
			word=True
		buff += char 
	return buff

def word_to_lower(s):
	word,buff = '',''
	for char in s:
		if not word and re.match('\w', char, re.UNICODE):
			char = char.lower()
			word=True
		buff += char 
	return buff

# ARGS -------------------

parser = argparse.ArgumentParser(description="OAI PMH 2.0 MARCXML Validator.")
parser.add_argument('--from', help='Records from. [YYYY-mm-dd HH:MM:SS]', type=valid_date, dest='from_date')
parser.add_argument('--until', help='Records until. [YYYY-mm-dd HH:MM:SS]', type=valid_date, dest='until_date')
args = parser.parse_args()

if not args.from_date: parser.error('argument --from is required.')
if not args.until_date: parser.error('argument --until is required.')

# OAI -------------------

registry = MetadataRegistry()
registry.registerReader('marc21', MarcXML)

oai = Client(OAI_URL, registry)

records = []

try:
	records = oai.listRecords(metadataPrefix='marc21', set=OAI_SET, from_=args.from_date, until=args.until_date)
except:
	records=[]

# MAIN -------------------

deletes = open(DELETES, 'w')

writer = MARCWriter(open('ECR.mrc', 'wb'))

for record in records:

	header = record[0]
	metadata = record[1]

	# write / skip deleted records
	if header.isDeleted():
		deletes.write(re.sub('^.*-(\d+)$', '\\1', header.identifier()) + '\n')
		print("Deleted.")
		continue

	# ident
	if '001' in metadata:
		ident = metadata['001'].value()
	else:
		print("Missing ident.")
		continue

	# CLB / ECS / ECR filter
	for F in metadata.get_fields('599'):
		if 'a' in F and F['a'] == 'CLB-CPK': break
	else:
		for F in metadata.get_fields('964'):
			if 'a' in F and F['a'] in ['ECS', 'ECR']: break
		else:
			print("CLB filter.")
			continue

	# timestamp
	timestamp = int(header.datestamp().timestamp())

	# LDR dup
	metadata.remove_fields('LDR')# Leader duplicate (Aleph)

	# Drop SYS
	metadata.remove_fields('SYS')# Invalid control field (Aleph)

	# Drop 022
	if metadata.leader[7] != 's': metadata.remove_fields('022')

	# Webarchiv
	for F in metadata.get_fields('856'):
		if 'y' in F:
			if F['y'] == 'Weabrchiv': F['y'] = 'Webarchiv'
			if F['y'] == 'WebArchiv': F['y'] = 'Webarchiv'
			if F['y'] == 'Webarhciv': F['y'] = 'Webarchiv'
			if F['y'] == 'Wenarchiv': F['y'] = 'Webarchiv'

	# Drop X
	X=False
	for F in metadata.get_fields('773'):
		if X and 'x' in F: F.delete_subfield('x')# drop more than one
		if 'x' in F: X = True# catch the first one

	# Drop Z
	Z=False
	for F in metadata.get_fields('773'):
		if Z and 'z' in F: F.delete_subfield('z')# drop more than one
		if 'z' in F: Z = True# catch the first one

	# MBK
	MBK=False
	if '044' in metadata:
		if 'a' in metadata['044']:
			if metadata['044']['a'] != 'xr': MBK=True
	if '008' in metadata:
		if metadata['008'].value()[15:17] != 'xr': MBK=True
	for F in metadata.get_fields('964'):
		if 'CLE' in F.value(): MBK=False
	if MBK:
		metadata.add_field(Field(tag='964', indicators=[' ',' '], subfields=['a', 'MBK']))

	# 594
	#if '245' in metadata and 'c' in metadata['245']:
	#	AUT = []
	#	for F in metadata.get_fields('100','700'):
	#		if len(F.get_subfields('4')) == 1 and F['4'] in ['aqt','ctb']: continue
	#		AUT.append(F)
	#	LHT = re.findall('<<[^<>]*>>', metadata['245']['c'])
	#	for F in metadata.get_fields('505'):
	#		if 'r' in F: LHT+=re.findall('<<[^<]*>>', F['r'])
	#	if len(LHT) > 0 and len(LHT) <= len(AUT) and '594' not in metadata:# tag
	#		for LH in LHT:
	#			if re.match('<<\[.*\]>>', LH): LH = 'Nepodepsáno.'# [] tag
	#			if LH == '<<>>': LH = name_invert(AUT[0]['a'], ident)# <<>> tag
	#			SUB=['x', re.sub('<<([^<>]*)>>', '\\1', LH)]
	#			SUB+=AUT[0].subfields
	#			metadata.add_field(Field(tag='594', indicators=[' ',' '], subfields=SUB))
	#			AUT=AUT[1:]# shift
	#	if len(LHT) == 0 and len(AUT) > 0 and '594' not in metadata:# no tag
	#		if len(AUT) == 1 and AUT[0].tag == '100':
	#			SUB = ['x', metadata['245']['c'].strip('.')]
	#			SUB += AUT[0].subfields
	#			metadata.add_field(Field(tag='594', indicators=[' ',' '], subfields=SUB))
	#		else:
	#			LHT = re.findall('[^,]*\[[^\[\]]*\][^,]*', metadata['245']['c'])
	#			if len(LHT) <= len(AUT):# overflow
	#				for LH in LHT:
	#					SUB=['x', LH.strip(' .')]
	#					SUB += AUT[0].subfields
	#					metadata.add_field(Field(tag='594', indicators=[' ',' '], subfields=SUB))
	#					AUT=AUT[1:]# shift

	# 100/505/600/700 remove << >>
	for F in metadata.get_fields('100', '505', '600', '700'):
		LHT = False
		SUB = F.subfields
		for i in range(0, len(SUB)):
			if re.findall('<<[^<>]*>>', SUB[i]):
				SUB[i] = re.sub('<<([^<>]*)>>', '\\1', SUB[i])
				LHT = True
		if LHT:
			F.subfields = SUB

	# 245c remove << >>
	if '245' in metadata and 'c' in metadata['245']:
		LHT = re.findall('<<[^<>]*>>', metadata['245']['c'])
		if LHT:
			metadata['245']['c'] = re.sub('<<([^<>]*)>>', '\\1', metadata['245']['c'])
		for LH in LHT:#
			SUB = re.findall('<<([^>[]+)', LH)
			if SUB:
				metadata.add_field(Field(tag='593', indicators=[' ',' '],
					subfields=['a', SUB[0].strip()]
				))


	# 592
	#if '630' in metadata and 'a' in metadata['630']:
	#	metadata.add_ordered_field(Field(tag='592', indicators=[' ',' '],
	#		subfields=['a', metadata['630']['a']]
	#	))

	#for F in metadata.get_fields('787'):
	#	if 't' in F and '4' in F:
	#		if 'a' in F:
	#			metadata.add_field(Field(tag='592', indicators=[' ',' '],
	#				subfields=['a', F['a'] + ': ' + F['t'], 'b', F['4']]
	#			))
	#		else:
	#			metadata.add_field(Field(tag='592', indicators=[' ',' '],
	#				subfields=['a', F['t'], 'b', F['4']]
	#			))

	# QUOTE
	BROKEN=False

	#BASE
	CNT=0
	NAME,DATA,CTEXT='','',''
	if '100' in metadata and 'a' in metadata['100']:
		if len(metadata['100']['a'].rstrip(',').split(',')) == 2:
			NAME = name_to_upper(metadata['100']['a'].rstrip(','), ident)
		else:
			NAME = metadata['100']['a']
		CNT+=1
	for F in metadata.get_fields('700'):
		if '4' in F and F['4'] == 'aut':
			if not NAME:
				NAME = name_to_upper(F['a'].rstrip(','), ident)
			else:
				NAME += u' – ' + name_to_upper(F['a'].rstrip(','), ident)
			CNT+=1
			if CNT == 3:
				NAME += ' et al.'
				break
		else:
			continue
	# NAME 100/700
	#if len(metadata.get_fields('100')) == 1 and '700' not in metadata and '710' not in metadata:
	#	if '245' in metadata and 'c' in metadata['245']:
	#		if '[=' in metadata['245']['c']:
	#			if re.findall('\[=(.+?)\]', metadata['245']['c']):
	#				LOW = re.findall('\[=(.+?)\]', metadata['245']['c'].strip())[0]
	#				NAME =  metadata['245']['c'].replace(LOW, name_to_upper(LOW, ident)).strip('. ')
	# 245
	if '245' in metadata:
		A = [sub for sub in metadata['245'].get_subfields('a')]
		B = [sub for sub in metadata['245'].get_subfields('b') if not re.match('^\[.*\]$', sub.strip('./ '))]
		NP = [sub for sub in metadata['245'].get_subfields('n','p')]

		DATA = re.sub('(?<![.])([.,:;/])(?![ .])' ,'\\1 ', ''.join(A + B + NP).strip('.:/ ')) + '. '
		
		if NAME: DATA = ': ' + DATA
		# 245c
		if 'c' in metadata['245']:
			if ';' in metadata['245']['c']:
				CTEXT =	re.sub('.*;(.*)', '\\1', metadata['245']['c']).strip('. ') + '. '
				# capitalize
				CTEXT = word_to_upper(CTEXT)
				# remove 245c page ref.
				CTEXT = re.sub(' \(s\.[^)]+\)', '', CTEXT)

	DATA = DATA.replace(' - ', u' – ')
	CTEXT = CTEXT.replace(' - ', u' – ')

	# 100a - 700a: 245abnp. 245c. 773t. 773g.
	TTEXT,GTEXT,URL = '','',''
	if metadata.leader[7] == 'b':
		# 773
		if '773' in metadata:
			# 773t (first..)
			if 't' in metadata['773']:
				TTEXT = metadata['773']['t'].strip() + '. '
				# URL
				if '[online]' in metadata['773']['t']:
					for F in metadata.get_fields('856'):
						if 'u' in F and 'y' in F and 'online' in F['y']:
							URL = ' URL: ' + F['u']
			# 773g (first..)
			if 'g' in metadata['773']:
				GTEXT = metadata['773']['g'].rstrip('.').strip() + '.'

		TTEXT = TTEXT.replace(' - ', u' – ')
		GTEXT = GTEXT.replace('-', u'–')

		BUFF = NAME + DATA + CTEXT + TTEXT + GTEXT + URL
		metadata.add_field(Field(tag='524', indicators=[' ',' '], subfields=['a', BUFF.replace('....', '...')]))

	# 100a - 700a: 245abnp. 245c. In: 773a: 773t. 773n. 773d, 773g.
	ATEXT,TTEXT,NTEXT,DTEXT,GTEXT,URL = '','','','','',''
	if metadata.leader[7] == 'a':
		# 773
		if '773' in metadata:
			# 100a - 700a: 245abnp. 245c. In: 787a: 773t. 787n. 787d, 773g.
			if 'a' not in metadata['773'] and 'd' not in metadata['773']:
				if 't' in metadata['773']:
					if '787' in metadata:
						MATCH=False
						for F in metadata.get_fields('787'):
							if 't' in F:
								if metadata['773']['t'][:10] in F['t']:
									MATCH=True
									# 787a (first..)
									if 'a' in F:
										ATEXT = F['a'].strip() + ': '
									# 773t (first..)
									if 't' in metadata['773']:
										TTEXT = metadata['773']['t'].strip() + '. '
										# URL
										if '[online]' in metadata['773']['t']:
											for U in metadata.get_fields('856'):
												if 'u' in U and 'y' in U and 'online' in U['y']:
													URL = ' URL: ' + U['u']
									# 787n (first..)
									if 'n' in F:
										NTEXT = word_to_upper(F['n']).strip() + '. '
									# 787d (first..)
									if 'd' in F:
										DTEXT = F['d'].strip() + ', '
									# 773g (first..)
									if 'g' in metadata['773']:
										GTEXT = metadata['773']['g'].rstrip('.').replace('-', u'–').strip() + '.'
										GTEXT = word_to_lower(GTEXT)
							else:
								BROKEN=True
						if not MATCH:
							BROKEN=True
					else:
						BROKEN=True
				else:
					BROKEN=True
			else:
				# 773a (first..)
				if 'a' in metadata['773']:
					ATEXT = metadata['773']['a'].strip() + ': '
				# 773t (first..)
				if 't' in metadata['773']:
					TTEXT = metadata['773']['t'].strip() + '. '
					# URL
					if '[online]' in metadata['773']['t']:
						for U in metadata.get_fields('856'):
							if 'u' in U and 'y' in U and 'online' in U['y']:
								URL = ' URL: ' + U['u']
				# 773n (first..)
				if 'n' in metadata['773']:
					NTEXT = word_to_upper(metadata['773']['n']).strip() + '. '
				# 773d (first..)
				if 'd' in metadata['773']:
					DTEXT = metadata['773']['d'].strip() + ', '
				# 773g (first..)
				if 'g' in metadata['773']:
					GTEXT = metadata['773']['g'].rstrip('.').replace('-', u'–').strip() + '.'
					GTEXT = word_to_lower(GTEXT)

		# 100a - 700a: 245abnp. 245c. In: 787a: 773t. 773n. 773d, 773g.
		TTEXT = TTEXT.replace(' - ', u' – ')
		GTEXT = GTEXT.replace('-', u'–')

		BUFF = NAME + DATA + CTEXT + 'In: ' + ATEXT + TTEXT + NTEXT + DTEXT + GTEXT + URL

		if not BROKEN:
			metadata.add_field(Field(tag='524', indicators=[' ',' '], subfields=['a', BUFF.replace('....', '...')]))

	# 100a - 700a: 245abnp. 245c. 260abc[264abc].
	ABC = ''
	if metadata.leader[7] == 'm':
		# ABC
		if '260' in metadata:
			ABC = ''.join([f.rstrip(' /') for f in metadata['260'].get_subfields('a','b','c')])
		if '264' in metadata:
			ABC = ''.join([f.rstrip(' /') for f in metadata['264'].get_subfields('a','b','c')])

		ABC = re.sub('(?<![.])([.,:;/])(?![ .])' ,'\\1 ', ABC).strip('. ') + '.'
		ABC = ABC.replace(' - ', u' – ')

		BUFF = NAME + DATA + CTEXT + ABC
		metadata.add_field(Field(tag='524', indicators=[' ',' '], subfields=['a', BUFF.replace('....', '...')]))

	# RE-ORDER
	metadata_sort = Record()
	metadata_sort.leader = metadata.leader
	for T in sorted(set(F.tag for F in metadata.fields)):
		for F in metadata.fields:
			if T == F.tag: metadata_sort.add_field(F)
	metadata = metadata_sort

	# WRITE
	writer.write(metadata)

# EXIT -------------------

writer.close()
deletes.close()
sys.exit(0)

