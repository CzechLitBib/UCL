#!/usr/bin/python
# -*- coding: utf-8 -*-

# INCLUDE -------------------

from __future__ import print_function

import sys,os,re

from pymarc import marcxml,Field,MARCWriter
from pymarc.record import Record

# VAR -------------------

#DATA='demo.xml'
DATA='ucla.xml'

TOTAL_100=0
SEVEN_100=0
TOTAL_600=0
SEVEN_600=0
TOTAL_700=0
SEVEN_700=0

#SIXTEEN=0

#file1 = open('100.csv','w')
#file2 = open('600.csv','w')
#file3 = open('700.csv','w')

link = open('link.txt','w')

writer = MARCWriter(open('file.mrc','wb'))

def validate(record):

	metadata = Record(force_utf8=True)
	metadata = record

	# LDR dup
	metadata.remove_fields('LDR')# LDR dup

#	if record['001'].value() == '001232606': record.remove_fields('506')#broken control field
#	if record['001'].value() == '001852470': return # skip broken encoding

#	global BUFF_100, BUFF_600, BUFF_700, TOTAL_100, SEVEN_100, TOTAL_600, SEVEN_600, TOTAL_700, SEVEN_700
#	global SIXTEEN

	IDENT = metadata['001'].value()

	# webarchiv
	for F in metadata.get_fields('856'):
		if 'y' in F:
			link.write(F['y'].encode('utf-8') + str('#') + str(IDENT) + '\n')
			if F['y'] == 'Weabrchiv': F['y'] = 'Webarchiv'
			if F['y'] == 'WebArchiv': F['y'] = 'Webarchiv'
			if F['y'] == 'Webarhciv': F['y'] = 'Webarchiv'
			if F['y'] == 'Wenarchiv': F['y'] = 'Webarchiv'

	# drop X
	X=False
	for F in metadata.get_fields('773'):
		if X and 'x' in F: F.delete_subfield('x')# drop more than one
		if 'x' in F: X = True# catch the first one

	# add MBK
	MBK=False
	if '044' in metadata:
		if 'a' in metadata['044']:
			if metadata['044']['a'] != 'xr': MBK=True
	if '008' in metadata:
		if metadata['008'].value()[15:17] != 'xr': MBK=True
	if MBK:
		if '964' in metadata:
			metadata['964'].add_subfield('a', 'MBK')
		else:
			metadata.add_ordered_field(Field(tag='964', indicators=[' ',' '], subfields=['a', 'MBK']))

	# broken
	if metadata['001'].value() == '001852470': return # skip the broken encoding

	writer.write(metadata)

#	if int(IDENT) >= int('002484593'):# 2020 only
#	if '005' in metadata and '008' in metadata:
#		if int(metadata['005'].value()[:4]) >= 2016:
#			if int(metadata['005'].value()[:4]) > int(metadata['008'].value()[:4]):
#				SIXTEEN+=1
#			if int(metadata['005'].value()[:4]) == int(metadata['008'].value()[:4]):
#				if int(metadata['005'].value()[4:7]) > int(metadata['008'].value()[4:7]):
#					SIXTEEN+=1

#	if int(IDENT) >= int('002484593'):# 2020 only
#		for F in metadata.get_fields('100'):
#			TOTAL_100+=1
#			if '7' in F: SEVEN_100+=1
#			file1.write(str(IDENT) + str(';') + '$$'.join(F.subfields).encode('utf-8') + '\n')
#	
#		for F in metadata.get_fields('600'):
#			TOTAL_600+=1
#			if '7' in F: SEVEN_600+=1
#			file2.write(str(IDENT) + str(';') + '$$'.join(F.subfields).encode('utf-8') + '\n')
#
#		for F in metadata.get_fields('700'):
#			TOTAL_700+=1
#			if '7' in F: SEVEN_700+=1
#			file3.write(str(IDENT) + str(';') + '$$'.join(F.subfields).encode('utf-8') + '\n')

#	writer.write(rec)

	#ALL = [ F['r'] for F in metadata.get_fields('912') if F.indicator1 == '2' and 'r' in F]

	#if len(ALL) == 1:
	#	BUFF+=(str(IDENT) + str(';') + metadata['245']['a'].encode('utf-8') + str(';' + ALL[0]) + '\n')
	#if len(ALL) > 1:
	#	BUFF+=(str(IDENT) + str(';') + metadata['245']['a'].encode('utf-8') + str(';' + ALL[0] + '#' + ALL[-1]) + '\n')

#	if '100' in record:
#		print(IDENT + '||' + record['100'].value())

	#if record.leader[7] == 'b':
	#	for F in metadata.get_fields('773'):
	#		if 't' in F and 'x' in F:
	#			if F['x'] == '0009-0468' and F['t'] == u'Česká literatura':
	#				BUFF+=str(IDENT) + chr(0x1F) + F.as_marc(encoding='utf-8') + '\n'
				#	print(F.as_marc(encoding='utf-8'))
					#for L in metadata.get_fields('856'):
					#	print(L.value().encode('utf-8'))
	# 600
 	#if len(metadata.get_fields('600')) == 1 and '7' not in metadata['600']:
	#	BIB=False
	#	for F in metadata.get_fields('655'):
	#		if 'a' in F and F['a'] in [
	#			u'biografické poznámky',
	 #			u'bio-bibliografické poznámky',
	#			u'biograficko-bibliografické poznámky',
	#			u'bibliografické poznámky',
	#			u'nekrology',
	#		 	u'medailony'
	#		]: BIB=True
	#	if BIB:
	#		six.write(str(IDENT) + '\n')

	# CLO
	#if metadata.leader[7] == 'b':
	#	if '100' in metadata and '700' not in metadata:
	#		for F in metadata.get_fields('773'):
	#			if '9' in F and 't' in F:
	#				if '245' in metadata and 'c' in metadata['245']:
	#					if '100' in metadata and 'a' in metadata['100']:
	#						clo.write(
	#							metadata['100']['a'].encode('utf-8') + '||' +
	#							metadata['245']['c'].encode('utf-8') + '||' +
	#							F['9'][:4].encode('utf-8') + '||' +
	#							F['t'].encode('utf-8') + '||' +
	#							F.value().encode('utf-8') + '||' +
	#							str(IDENT) + '\n'
	#						)

	#if IDENT > 
	#	print("Time.")
	#sys.exit(1)

	#if 'SIF' in metadata:
	#	if 'a' in metadata['SIF']: SIF = metadata['SIF']['a'].encode('utf-8')
	#else:
	#	SIF = ''

	# CSV
	# SysNo SIF i a t n d b k h z x y 4

	#if COUNTER == 10000: sys.exit(1)

	#COUNTER+=1

	#for F in metadata.get_fields('787'):
	#	PAYLOAD=''
	#	PAYLOAD+=str(IDENT) + '|' + SIF
	#	for SUB in ('i', 'a', 't', 'n', 'd', 'b', 'k', 'h', 'z', 'x', 'y', '4'):
	#		if SUB in F:
	#			PAYLOAD+= '|' + '@'.join([s.encode('utf-8') for s in F.get_subfields(SUB)])
	#		else:
	#			PAYLOAD+='|'
	#	PAYLOAD+='\n'
	#	csv_787.write(PAYLOAD)
	#return
			
	#	VAL = re.sub('( +,| +;| +:)$','', VAL).strip().strip('[').strip(']')
	#	csv_260a.write(str(IDENT) + ';' + VAL.encode('utf-8') + '\n')
	#	for VAL in F.get_subfields('z'):
	#		VAL = re.sub('( ?,| ?;| ?:)$','', VAL).strip().strip('[').strip(']')
	#		csv_260b.write(str(IDENT) + ';' + VAL.encode('utf-8') + '\n')
	#	for F in metadata.get_fields('264'):
	#		for VAL in F.get_subfields('a'):
	#			VAL = re.sub('( +,| +;| +:)$','', VAL).strip().strip('[').strip(']')
	#			csv_264a.write(str(IDENT) + ';' + VAL.encode('utf-8') + '\n')
	#	for VAL in F.get_subfields('b'):
	#		VAL = re.sub('( ?,| ?;| ?:)$','', VAL).strip().strip('[').strip(']')
	#		csv_264b.write(str(IDENT) + ';' + VAL.encode('utf-8') + '\n')

	#	if 'SIF' in metadata:
	#		if 'a' in metadata['SIF']: SIF = metadata['SIF']['a'].encode('utf-8')
	#	else:
	#		SIF = ''

	#	if metadata.leader[7]  == 'b':
	#		for F in metadata.get_fields('773'):
	#			T,X,G,Q,N='','','','',''
	#			if 't' in F: T = F['t'].encode('utf-8')
	#			if 'x' in F: X = F['x'].encode('utf-8')
	#			if 'g' in F: G = F['g'].encode('utf-8')
	#			if 'q' in F: Q = F['q'].encode('utf-8')
	#			if '9' in F: N = F['9'].encode('utf-8')
	#			csv_773.write(str(IDENT) + '|' + SIF  + '|' + T + '|' + X  + '|' + G + '|' + Q + '|' + N + '\n')
	#	return

	#	if 'SIF' in metadata:
	#		if 'a' in metadata['SIF']: SIF = metadata['SIF']['a'].encode('utf-8')
	#	else
	#		SIF = ''

# MAIN -------------------

#record = Record()

#record.leader = '     nam a22     4i 4500'
#field = Field(tag = '001', data='002524717')
#record.add_ordered_field(field)
#field = Field(tag = '015', indicators = [' ',' '], subfields = ['a', 'cnb000000000'])
#record.add_ordered_field(field)

#validate(record)

marcxml.map_xml(validate, DATA)

#with = open('100.csv','w') as ucl:
#	ucl.write(BUFF_100)
#with = open('600.csv','w') as ucl:
#	ucl.write(BUFF_600)
#with open('700.csv','w') as ucl:
#	ucl.write(BUFF_700)

link.close()

writer.close()

#file1.close()
#file2.close()
#file3.close()

#print('TOTAL 100:' + str(TOTAL_100))
#print('SEVEN 100:' + str(SEVEN_100))
#print('TOTAL 600:' + str(TOTAL_600))
#print('SEVEN 600:' + str(SEVEN_600))
#print('TOTAL 700:' + str(TOTAL_700))
#print('SEVEN 700:' + str(SEVEN_700))

#print(str(SIXTEEN))

# EXIT -------------------

sys.exit(0)

