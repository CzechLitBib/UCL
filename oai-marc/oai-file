#!/usr/bin/python
# -*- coding: utf-8 -*-

# INCLUDE -------------------

from __future__ import print_function

import traceback,StringIO,requests,lxml.html,time,sys,os,re

from pymarc import marcxml,Field,MARCWriter,MARCReader, XMLWriter
from pymarc.record import Record

# VAR -------------------

#DATA='demo.xml'
#DATA='uclec.xml'
DATA='uclo.xml'
#DATA='ucla.xml'
#DATA='uclo_koha.xml'
#DATA='koha_024.xml'
#DATA='ucla_citace.mrc'
#DATA='xedice.mrc'
#DATA='book.xml'
#DATA='CLO-opr.mrc'

#TOTAL_100=0
#SEVEN_100=0
#TOTAL_600=0
#SEVEN_600=0
#TOTAL_700=0
#SEVEN_700=0

#BUFF=''

#SIXTEEN=0
#TOTAL=0
#COUNTER=0


#csv_773 = open('773.csv', 'w')
#csv_773.write('IDENT|SIF|LDR|VUFIND|VALUE|a|t|x|n|d|b|k|y|g|q|9|z\n')

#csv_787 = open('787.csv', 'w')
#csv_787.write('IDENT|SIF|LDR|VUFIND|VALUE|i|a|t|n|d|b|k|h|z|y|4|x\n')
	
file0 = open('clo_400bc.csv', 'w')
file1 = open('clo_500bc.csv', 'w')
#file2 = open('964_245.csv', 'w')
#file3 = open('output/SIF.txt', 'w')
#file4 = open('output/158.csv', 'w')
#file5 = open('output/109.csv', 'w')
#file6 = open('output/100.csv', 'w')
#file7 = open('output/166.csv', 'w')
#file8 = open('output/046.csv', 'w')
#file9 = open('output/141.csv', 'w')
#file10 = open('output/245.csv', 'w')

#aleph = open('505.aleph', 'w')
#xml = XMLWriter(open('koha_024.xml', 'w'))
#writer = MARCWriter(open('ucla.mrc', 'wb'))

# KOHA ---------

#KOHAMAP={}

#with open('koha_wiki.csv', 'r') as f:
#	for line in f:
#		data = line.split(';')
#		KOHAMAP[data[0]] = data[1:]

# WAYBACK ---------

#link = open('link.txt', 'r')
#wayback = open('wayback.csv', 'r')
#aleph = open('wayback.aleph', 'w')

#WAY={}
#for LINE in wayback:
#	ID=LINE.split('##')[0].strip()
#	ORIG=LINE.split('##')[1].strip()
#	ARCH=LINE.split('##')[2].strip()
	
#	if ID not in WAY: WAY[ID] = {}
#	WAY[ID]['ORIG']=ORIG
#	WAY[ID]['ARCH']=ARCH

# 505 ---------

#INDEX=1

# WAYBACK ---------

#writer1 = MARCWriter(open('ucla_citace_bez_edice.mrc', 'wb'))
#writer2 = MARCWriter(open('ucla_citace_edice.mrc', 'wb'))

#writer1 = MARCWriter(open('clo964_1.mrc', 'wb'))
#writer2 = MARCWriter(open('clo964_2.mrc', 'wb'))
#writer3 = MARCWriter(open('clo964_3.mrc', 'wb'))
#writer4 = MARCWriter(open('clo964_4.mrc', 'wb'))

# BASE ---------

#DATADIR='/var/www/html/964'
#BASE=['B12', 'B45', 'B70', 'B80', 'B97', 'CLE', 'INT', 'RET', 'SMZ', 'PWC', 'MBK']

# BASE ---------

#reader = MARCReader(file('vufind-2021-03-04.mrc'))
#for record in reader:
#	print(record['001'].value())

#reader.close()

#reader = MARCReader(file(DATA))

#for record in reader:
#	metadata = record

#	for F in metadata.get_fields('100'):
#		if '7' in F:
#			print(F.value().encode('utf-8'))

#	print(metadata['001'].value())

#	if metadata.leader[7] == 's':
#		writer2.write(metadata)
#	else:
#		writer1.write(metadata)

#reader.close()
#sys.exit(1)

def name_switch(s):
	s = s.strip(', ')
	return s.split(' ')[-1] + ', ' + ' '.join(s.split(' ')[:-1])

def name_to_upper(s,ID):
	if len(s.split(',')) == 2:
		return s.split(',')[0].strip().upper() + ', ' + s.split(',')[1].strip() 
	else:
		if '[=' in s: print(ID + '#Multiple comma.')
	return s

def word_to_upper(s):
	word,buff = '',''
	for char in s:
		if not word and re.match('\w', char, re.UNICODE):
			char = char.upper()
			word=True
		buff += char 
	return buff

def word_to_lower(s):
	word,buff = '',''
	for char in s:
		if not word and re.match('\w', char, re.UNICODE):
			char = char.lower()
			word=True
		buff += char 
	return buff

def citace(record, fiveofive, page):

	metadata = record

	IDENT = metadata['001'].value()

	#PREFACE
	PREFACE,PRENAME='',''
	#if '100' in record and 'a' in record['100'] and '245' in record and 'a' in record['245']:
	#	if len(metadata['100']['a'].rstrip(',').split(',')) == 2:
	#		PRENAME = name_to_upper(metadata['100']['a'].rstrip(','), IDENT)
	#	else:
	#		PRENAME = metadata['100']['a']
	#
	#	PREFACE = PRENAME + ': ' + re.sub('(.*[^!?])$','\\1.', metadata['245']['a'].strip('=:/ ')) + ' In: '
	if 't' in fiveofive and 'r' in fiveofive:
		PRENAME = name_to_upper(name_switch(fiveofive['r']), IDENT)
		PREFACE = PRENAME + ': ' + re.sub('(.*)\[.+\]$','\\1', fiveofive['t'].strip('/ ')).strip() + ' In: '

	#BASE
	CNT=0
	NAME,DATA,CTEXT='','',''
	if '100' in metadata and 'a' in metadata['100']:
		if len(metadata['100']['a'].rstrip(',').split(',')) == 2:
			NAME = name_to_upper(metadata['100']['a'].rstrip(','), IDENT)
		else:
			NAME = metadata['100']['a']
		CNT+=1
	for F in metadata.get_fields('700'):
		if '4' in F and F['4'] == 'aut':
			if not NAME:
				NAME = name_to_upper(F['a'].rstrip(','), IDENT)
			else:
				NAME += u' – ' + name_to_upper(F['a'].rstrip(','), IDENT)
			CNT+=1
			if CNT == 3:
				NAME += ' et al.'
				break
		else:
			continue

	# NAME 100/700
	#if len(metadata.get_fields('100')) == 1 and '700' not in metadata and '710' not in metadata:
	#	if '245' in metadata and 'c' in metadata['245']:
	#		if '[=' in metadata['245']['c']:
	#			if re.findall('\[=(.+?)\]', metadata['245']['c']):
	#				LOW = re.findall('\[=(.+?)\]', metadata['245']['c'].strip())[0]
	#				NAME = metadata['245']['c'].replace(LOW, name_to_upper(LOW, IDENT)).strip('. ')
	#
	# 245
	if '245' in metadata:
		A = [sub for sub in metadata['245'].get_subfields('a')]
		B = [re.sub('(.*):.*' ,'\\1', sub).strip() for sub in metadata['245'].get_subfields('b') if not re.match('^\[.*\]$', sub.strip('./ '))]
		NP = [sub for sub in metadata['245'].get_subfields('n','p')]

		DATA = re.sub('(?<![.])([.,:;/])(?![ .])' ,'\\1 ', ''.join(A + B + NP).strip('.:/ ')) + '. '

		if NAME: DATA = ': ' + DATA
		# 245c
		if 'c' in metadata['245'] and ';' not in metadata['245']['c'] and metadata['245']['c'][0].islower():
			CTEXT =	re.sub('.*;(.*)', '\\1', metadata['245']['c']).strip('. ') + '. '
			# capitalize
			CTEXT = word_to_upper(CTEXT)
			# remove 245c page ref.
			CTEXT = re.sub(' \(s\.[^)]+\)', '', CTEXT)

	DATA = DATA.replace(' - ', u' – ')
	CTEXT = CTEXT.replace(' - ', u' – ')

	# 100a - 700a: 245abnp. 245c. 260abc[264abc].
	ABC = ''
	if metadata.leader[7] == 'm':
		# ABC
		if '260' in metadata:
			ABC = ''.join([f.rstrip(' /') for f in metadata['260'].get_subfields('a','b','c')])
		if '264' in metadata:
			ABC = ''.join([f.rstrip(' /') for f in metadata['264'].get_subfields('a','b','c')])

		ABC = re.sub('(?<![.])([.,:;/])(?![ .])' ,'\\1 ', ABC).strip('. ') + '.'
		ABC = ABC.replace(' - ', u' – ')

		BUFF = PREFACE + NAME + DATA + CTEXT + ABC
		# add page
		if page:
			BUFF.strip().rstrip('.')
			BUFF = re.sub('(.*)\.$', '\\1, s. '+ page + '.', BUFF.strip())
		return(Field(tag='524', indicators=[' ',' '], subfields=['a', BUFF.replace('....', '...')]))

def validate(record):

	metadata = record

# ------------------------------------------------------

#	global BUFF
#	global BUFF_100, BUFF_600, BUFF_700, TOTAL_100, SEVEN_100, TOTAL_600, SEVEN_600, TOTAL_700, SEVEN_700
#	global SIXTEEN
#	global INDEX

	# LDR dup
#	metadata.remove_fields('LDR')# LDR dup

#	if metadata['001'].value() == '001232606': metadata.remove_fields('506')# UCLEC broken control field
#	if metadata['001'].value() == '001852470': return # UCLA skip broken encoding

	# UCLEC drop records [obsolate]
	#if metadata['001'].value() in ['001676249','002194963','002265478','001232724','002549375','001232855']: return
	#if metadata['001'].value() == '001232855': return

	# UCLEC: 912 -> 913 ind1 = 2
	#for F in [f for f in metadata.get_fields('912') if f.indicator1 == '2']: F.tag = '913'

	# UCLEC: 912 -> 911 ind1 = ' ' ind2 = ' '
	#for F in [f for f in metadata.get_fields('912') if f.indicator1 + f.indicator2 == '  ']: F.tag = '911'

	# UCLEC drop 506 fields
	#metadata.remove_fields('506')

	# UCLA:  webarchiv
#	for F in metadata.get_fields('856'):
#		if 'y' in F:
#			if F['y'] == 'Weabrchiv': F['y'] = 'Webarchiv'
#			if F['y'] == 'WebArchiv': F['y'] = 'Webarchiv'
#			if F['y'] == 'Webarhciv': F['y'] = 'Webarchiv'
#			if F['y'] == 'Wenarchiv': F['y'] = 'Webarchiv'

	# UCLA: drop X
#	X=False
#	for F in metadata.get_fields('773'):
#		if X and 'x' in F: F.delete_subfield('x')# drop more than one
#		if 'x' in F: X = True# catch the first one

	# UCLA: add MBK
#	MBK=False
#	if '044' in metadata:
#		if 'a' in metadata['044']:
#			if metadata['044']['a'] != 'xr': MBK=True
#	if '008' in metadata:
#		if metadata['008'].value()[15:17] != 'xr': MBK=True
#	for F in metadata.get_fields('964'):
#		if 'CLE' in F.value(): MBK=False
#	if MBK:
#		metadata.add_ordered_field(Field(tag='964', indicators=[' ',' '], subfields=['a', 'MBK']))

	# 599 UCLO special
	#for F in metadata.get_fields('599'):
	#	if 'a' in F:
	#		BUFF+=F['a'] + str('|') + IDENT + '\n'

	# UCLO 599a
#	XEDICE=False
#	for F in metadata.get_fields('599'):
#		if 'a' in F and F['a'] == 'xedice':
#			XEDICE=True
#	if XEDICE:
#		COUNTER+=1
#		metadata.add_ordered_field(Field(tag='964', indicators=[' ',' '], subfields=['a', 'XEDICE']))
#		writer.write(metadata)

	# write MRC
#	writer.write(metadata)

#	return

# ------------------------------------------------------
# BASE
# ------------------------------------------------------

	# LDR dup
#	metadata.remove_fields('LDR')# LDR dup

#	IDENT = metadata['001'].value()

#	if '964' in metadata and 'FMT' in metadata:# 990 -> FMT

#		for F in metadata.get_fields('964'):
#			base = F.value()
#			if base in BASE:
#				sub_base = metadata['FMT'].value()
#				try:
#					os.mkdir(DATADIR + '/'+ base)
#				except: pass
#				try:
#					os.mkdir(DATADIR + '/'+ base + '/' + sub_base)
#				except: pass
		
#				with open(DATADIR + '/'+ base + '/' + sub_base + '/' + base + '_' + sub_base + '.aleph', 'a', 0) as aleph:
					# LEADER
#					aleph.write(str(IDENT) + ' LDR   L ' + metadata.leader.replace(' ', '^').encode('utf-8') + '\n')
#					for F in metadata:
#						if hasattr(F, 'indicators'):
#							# REGULAR FIELD
#							SUB=''
#							for i in range(0, len(F.subfields)/2):
#								SUB+='$$' + F.subfields[i*2] + F.subfields[i*2+1]
#							aleph.write(str(IDENT + ' ' + F.tag + F.indicator1 + F.indicator2 + ' L ') + SUB.encode('utf-8') + '\n')
#						else:
							# SYSTEM FIELD
#							aleph.write(str(IDENT) + ' ' + F.tag + '   L ' + F.value().replace(' ','^').encode('utf-8') + '\n')

# ------------------------------------------------------
# GENERIC
# ------------------------------------------------------


 	#UCLA remove << >>

#	print(metadata)

#	for F in metadata.get_fields('100', '600', '700'):
#		LHT = False
#		SUB = F.subfields
#		for i in range(0, len(SUB)):
#			if re.findall('<<[^<]*>>', SUB[i]):
#				SUB[i] = re.sub('<<([^<]*)>>', '\\1', SUB[i])
#				LHT = True
#		if LHT:
#			F.subfields = SUB
#
#	if '245' in metadata and 'c' in metadata['245']:
#		LHT = re.findall('<<[^<]*>>', metadata['245']['c'])
#		if LHT: metadata['245']['c'] = re.sub('<<([^<]*)>>', '\\1', metadata['245']['c'])	
#		for LH in LHT:
#			metadata.add_ordered_field(Field(tag='593', indicators=[' ',' '], subfields=['a',  re.sub('<<([^<]*)>>', '\\1', LH)]))
#
#	print(metadata)

#	return

	# CLO 100/400/500bc

	if '001' in metadata:
		IDENT = metadata['001'].value()
	else:
		IDENT = ''

	for F in metadata.get_fields('400'):
		if 'b' in metadata['400'] and 'c' in metadata['400']:
			SUB=''
			for i in range(0, len(F.subfields)/2):
				SUB+='$$' + F.subfields[i*2] + F.subfields[i*2+1]
			file0.write(str(IDENT + ';BC;') + SUB.encode('utf-8') + '\n')
		elif 'b' in metadata['400']:
			SUB=''
			for i in range(0, len(F.subfields)/2):
				SUB+='$$' + F.subfields[i*2] + F.subfields[i*2+1]
			file0.write(str(IDENT + ';B;') + SUB.encode('utf-8') + '\n')
	
		elif 'c' in metadata['400']:
			SUB=''
			for i in range(0, len(F.subfields)/2):
				SUB+='$$' + F.subfields[i*2] + F.subfields[i*2+1]
			file0.write(str(IDENT + ';C;') + SUB.encode('utf-8') + '\n')

	for F in metadata.get_fields('500'):
		if 'b' in metadata['500'] and 'c' in metadata['500']:
			SUB=''
			for i in range(0, len(F.subfields)/2):
				SUB+='$$' + F.subfields[i*2] + F.subfields[i*2+1]
			file1.write(str(IDENT + ';BC;') + SUB.encode('utf-8') + '\n')
		elif 'b' in metadata['500']:
			SUB=''
			for i in range(0, len(F.subfields)/2):
				SUB+='$$' + F.subfields[i*2] + F.subfields[i*2+1]
			file1.write(str(IDENT + ';B;') + SUB.encode('utf-8') + '\n')
	
		elif 'c' in metadata['500']:
			SUB=''
			for i in range(0, len(F.subfields)/2):
				SUB+='$$' + F.subfields[i*2] + F.subfields[i*2+1]
			file1.write(str(IDENT + ';C;') + SUB.encode('utf-8') + '\n')
	
	return

	# KOHA

#	global COUNTER, TOTAL

#	TOTAL+=1

#	if IDENT in KOHAMAP:
#		COUNTER+=1
#		for i in range(0, len(KOHAMAP[IDENT])/2):
#			metadata.add_ordered_field(Field(tag='024', indicators=['7',' '], subfields=['a', str(KOHAMAP[IDENT][2*i+1]).strip(), '2', str(KOHAMAP[IDENT][2*i]).strip()]))
#		xml.write(metadata)

#	print(metadata)

#	return

#	for F in metadata.get_fields('100'):
#		if '7' in metadata['100']:
#			print(IDENT + ';' + metadata['100']['7'])

#	for F in metadata.get_fields():
#		if F.tag not in ['100', '600', '700']:
#			if '<' in F.value() or '>' in F.value():
#				if F.tag != '245' and F.tag != '773':
#					print(IDENT + '->' + F.tag)
#				if F.tag == '245':
#					if 'c' in F:
#						if '<' not in F['c'] and '>' not in F['c']:
#							print(IDENT + '->' + F.tag)
#					else:
#						print(IDENT + '->' + F.tag)
#				if F.tag == '773':
#					if 'q' in F:
#						if '<' not in F['q'] and '>' not in F['q']:
#							print(IDENT + '->' + F.tag)
#					else:
#						print(IDENT + '->' + F.tag)
#						
#	return

#	DATA=IDENT + ';'

#	if '260' in metadata and 'c' in metadata['260']:
#		DATA += metadata['260']['c'].encode('utf-8') + ';'
#	else:
#		DATA += ';'

#	PASS=0
#	for F in metadata.get_fields('264'):
#		if 'c' in F: PASS+=1
#	if PASS > 0:
#		ALL = [F['c'] for F in metadata.get_fields('264') if 'c' in F]
#		if len(ALL) == 1:
#			DATA +=	ALL[0].encode('utf-8') + ';'
#		else:
#			DATA +=	'#'.join(ALL).encode('utf-8') + ';'
#	else:
#		DATA += ';'

#	if '008' in metadata:
#		DATA += metadata['008'].value().encode('utf-8') + ';'
#	else:
#		DATA += ';'

#	PASS=0
#	for F in metadata.get_fields('773'):
#		if '9' in F: PASS+=1
#	if PASS > 0:
#		ALL = [F['9'] for F in metadata.get_fields('773') if '9' in F]
#		if len(ALL) == 1:
#			DATA +=	ALL[0].encode('utf-8')
#		else:
#			DATA +=	'#'.join(ALL).encode('utf-8')

#	file0.write(DATA + '\n')

#	return

	# 245c
#	ROLE=True
#	for F in metadata.get_fields('700'):
#		if '4' in F and 'aut' not in F.get_subfields('4'): ROLE=False
#	for F in metadata.get_fields('506'):
#		if 'a' in F and F['a'] == '162': ROLE=True
#	if '100' in metadata and 'ive' in metadata['100'].get_subfields('4'): ROLE=True
#	if not ROLE and '100' in metadata:
#		if '245' in metadata and 'c' in metadata['245']:
#			if ';' not in metadata['245']['c']:
#				file0.write('https://vufind.ucl.cas.cz/Record/' + str(IDENT) + '#details\n')
#	return

	#IDENT = metadata['001'].value()

	#for F in metadata.get_fields('505'):
	#	if len(F.get_subfields('t')) >=2:
	#		file0.write(str(IDENT) + 'T\n')
	#	if len(F.get_subfields('r')) >=2:
	#		file0.write(str(IDENT) + 'R\n')
	#	if len(F.get_subfields('g')) >=2:
	#		file0.write(str(IDENT) + 'G\n')
	#return

#	if '964' in metadata and '520' in metadata:
#		BASE=''
#		for F in metadata.get_fields('964'):
#			if F['a'][0].isupper():
#				BASE=F['a']
#				break
#		file0.write(str(IDENT + ';' + metadata.leader[7] + ';') + BASE.encode('utf-8') + str(';') + metadata['520']['a'].encode('utf-8') + '\n')
#	if '964' in metadata and '500' in metadata:
#		BASE=''
#		for F in metadata.get_fields('964'):
#			if F['a'][0].isupper():
#				BASE=F['a']
#				break
#		for F in metadata.get_fields('500'):
#			file1.write(str(IDENT + ';' + metadata.leader[7] + ';') + BASE.encode('utf-8') + str(';') + F['a'].encode('utf-8') + '\n')

#	if '964' in metadata and '245' in metadata:
#		BASE=''
#		for F in metadata.get_fields('964'):
#			if F['a'][0].isupper():
#				BASE=F['a']
#				break
#		file2.write(str(IDENT + ';' + metadata.leader[7] + ';') + BASE.encode('utf-8') + str(';') + metadata['245'].value().encode('utf-8') + '\n')

#	return

#	if metadata.leader[7] == 'a':
#		if '787' not in metadata:
#			for F in metadata.get_fields('773'):
#				file0.write(str(IDENT) + str(';') + F['t'].encode('utf-8') + str(';') + F.value().encode('utf-8') + '\n') 		

#	return

	#if metadata.leader[7] == 'm': print(str(IDENT))

	#return

	# 520
#	if '520' not in metadata:
#		file0.write('https://aleph22.lib.cas.cz/F/?func=direct&doc_number=' + IDENT + '&local_base=AV\n')
	# 655
#	if '655' not in metadata:
#		file1.write('https://aleph22.lib.cas.cz/F/?func=direct&doc_number=' + IDENT + '&local_base=AV\n')
	# 005
#	if '005' not in metadata:
#		file2.write('https://aleph22.lib.cas.cz/F/?func=direct&doc_number=' + IDENT + '&local_base=AV\n')
	# SIF
#	if 'SIF' not in metadata:
#		file3.write('https://aleph22.lib.cas.cz/F/?func=direct&doc_number=' + IDENT + '&local_base=AV\n')
	# 158
#	if '245' in metadata:
#		if 'b' in metadata['245']:
#			if re.match('^\(.*\)$', metadata['245']['b'].strip('/ ')):
#				SUB=''
#				for i in range(0, len(metadata['245'].subfields)/2):
#					SUB+='$$' + metadata['245'].subfields[i*2] + metadata['245'].subfields[i*2+1]
#				file4.write(str('https://aleph22.lib.cas.cz/F/?func=direct&doc_number=' + IDENT + '&local_base=AV' + '|') + SUB.encode('utf-8') + '\n')
	
#	return
	# 109
#	if metadata.leader[7] == 'b':
#		if '008' in metadata:
#			DATA = metadata['008'].value()[7:15].strip()
#			if '773' in metadata:
#				if '9' in metadata['773']:
#					NINE=False
#					if DATA == metadata['773']['9']: NINE=True
#					if '-' in metadata['773']['9']:
#						if DATA == re.sub('^(.*)-.*','\\1', metadata['773']['9']): NINE=True
#						if DATA == metadata['773']['9'].replace('-',''): NINE=True
#					if not NINE:
#						G=''
#						if 'g' in metadata['773']: G = str('|') + metadata['773']['g'].encode('utf-8')
#						file5.write(str('https://aleph22.lib.cas.cz/F/?func=direct&doc_number=' + IDENT + '&local_base=AV' + '|' + metadata['008'].value()[7:15].strip() + '|') +
#						metadata['773']['9'].encode('utf-8') + G + '\n'
#						)
	# 100
#	for TAG in ('600', '610', '611', '630' ,'648', '650', '651', '655'):
#		for F in metadata.get_fields(TAG):
#			if F.indicator2 == '4':
#				if '7' in F or '2' in F and F['2'] == 'czenas':
#					SUB=''
#					for i in range(0, len(F.subfields)/2):
#						SUB+='$$' + F.subfields[i*2] + F.subfields[i*2+1]
#					file6.write(str('https://aleph22.lib.cas.cz/F/?func=direct&doc_number=' + IDENT + '&local_base=AV' + '|' + TAG + '|') + SUB.encode('utf-8') + '\n')
	# 166
#	if '245' in metadata:
#		if 'c' in metadata['245']:
#			if re.match('.*s\. [0-9]+.*', metadata['245']['c']):
#				SUB=''
#				for i in range(0, len(metadata['245'].subfields)/2):
#					SUB+='$$' + metadata['245'].subfields[i*2] + metadata['245'].subfields[i*2+1]
#				file7.write(str('https://aleph22.lib.cas.cz/F/?func=direct&doc_number=' + IDENT + '&local_base=AV' + '|') + SUB.encode('utf-8') + '\n')

	# 046
#	for F in metadata.get_fields('773'):
#		if F.indicator1 + F.indicator2 != '0 ':
#			SUB=''
#			for i in range(0, len(metadata['245'].subfields)/2):
#				SUB+='$$' + metadata['245'].subfields[i*2] + metadata['245'].subfields[i*2+1]
#			file8.write(str('https://aleph22.lib.cas.cz/F/?func=direct&doc_number=' + IDENT + '&local_base=AV' + '|') + SUB.encode('utf-8') + '\n')

	# 141

#	if metadata.leader[7] == 'n':
#		if '100' in metadata and '773' in metadata:
#			if 'c' in metadata['100']:
#				if re.match('^\[.*\]$', metadata['100']['c']):
#					C = re.sub('^\[(.*)\]$', '\\1', metadata['100']['c']).strip()
					#print(C.encode('utf-8'))
#					CS = re.sub('^([^(]+).*', '\\1', C).strip()
					#print(CS.encode('utf-8'))
#					F = [F['t'] for F in metadata.get_fields('773')[:1] if 't' in F]
					#print(str(F).encode('utf-8'))
#					FS = [re.sub('^([^\[]+).*','\\1', S['t']).strip() for S in metadata.get_fields('773')[:1] if 't' in S]
					#print(str(FS).encode('utf-8'))
#					if F and C not in F[0]:
#						if FS and CS not in FS[0]:
					#		print(metadata)
					#		raw_input('press enter..')
#							SUB,T='',''
#							for i in range(0, len(metadata['100'].subfields)/2):
#								SUB+='$$' + metadata['100'].subfields[i*2] + metadata['100'].subfields[i*2+1]
#							for F in metadata.get_fields('773')[-1:]:
#								if 't' in F: T = str('|') + F['t'].encode('utf-8')
#							file9.write(str('https://aleph22.lib.cas.cz/F/?func=direct&doc_number=' + IDENT + '&local_base=AV' + '|') + SUB.encode('utf-8') + T + '\n')

#	return
	# 245
#	if '245' in metadata:
#		C=''
#		if 'c' in metadata['245']: C = str('|') + metadata['245']['c'].encode('utf-8')
#		metadata['245'].delete_subfield('c')
#		SUB=''
#		for i in range(0, len(metadata['245'].subfields)/2):
#				SUB+='$$' + metadata['245'].subfields[i*2] + metadata['245'].subfields[i*2+1]
#		file10.write(str('https://aleph22.lib.cas.cz/F/?func=direct&doc_number=' + IDENT + '&local_base=AV' + '|') + SUB.encode('utf-8') + C + '\n')

#	return

#	if IDENT  == '002553052': print(metadata)

#	for TAG in ('100','110','111','600','610','630','648','650','651','655','700','710','711'):
#		for F in metadata.get_fields(TAG):
#			if '7' in F and re.match('^aun.*', F['7']):
#				print(str(IDENT + '#' + TAG + '#') + F.value().encode('utf-8'))

	#if 'SIF' in metadata:
	#	if 'a' in metadata['SIF']: SIF = metadata['SIF']['a'].encode('utf-8')
	#else:
	#	SIF = ''

#	if '005' in metadata and '008' in metadata:
#		if int(metadata['005'].value()[:4]) >= 2016:
#			if int(metadata['005'].value()[:4]) > int(metadata['008'].value()[:4]):
#				SIXTEEN+=1
#			if int(metadata['005'].value()[:4]) == int(metadata['008'].value()[:4]):
#				if int(metadata['005'].value()[4:7]) > int(metadata['008'].value()[4:7]):
#					SIXTEEN+=1

#	if int(IDENT) >= int('002484593'):# 2020 only
#		for F in metadata.get_fields('100'):
#			TOTAL_100+=1
#			if '7' in F: SEVEN_100+=1
#			file1.write(str(IDENT) + str(';') + '$$'.join(F.subfields).encode('utf-8') + '\n')
#	
#		for F in metadata.get_fields('600'):
#			TOTAL_600+=1
#			if '7' in F: SEVEN_600+=1
#			file2.write(str(IDENT) + str(';') + '$$'.join(F.subfields).encode('utf-8') + '\n')
#
#		for F in metadata.get_fields('700'):
#			TOTAL_700+=1
#			if '7' in F: SEVEN_700+=1
#			file3.write(str(IDENT) + str(';') + '$$'.join(F.subfields).encode('utf-8') + '\n')

#	writer.write(rec)

	# 912
#	if '912' in metadata:
#		if '245' in metadata:
#			if 'a' in metadata['245']:
#				part_0 = metadata['245']['a'].encode('utf-8')
#			else:
#				part_0 = ''
#			part_1 = '$$'.join(metadata['245'].subfields).encode('utf-8') 
#		else:
#			part_1 = ''
#
#		if '246' in metadata:
#			part_2 = '$$'.join(metadata['246'].subfields).encode('utf-8') 
#		else:
#			part_2 = ''
#
#		ALL1 = [ F['r'] for F in metadata.get_fields('912') if F.indicator1 == ' ' and F.indicator2 == ' ' and 'r' in F]
#		if len(ALL1) == 1:
#			part_3 = ALL1[0]
#		elif len(ALL1) > 1:
#			part_3 = '#'.join(ALL1)
#		else:
#			part_3 = ''
#
#		ALL2 = [ F['r'] for F in metadata.get_fields('912') if F.indicator1 == '2' and 'r' in F]
#		if len(ALL2) == 1:
#			part_4 = ALL2[0]
#		elif len(ALL2) > 1:
#			part_4 = ALL2[0] + '#' + ALL2[-1]
#		else:
#			part_4 = ''

#		BUFF+=(
#			str(IDENT) + '\t' +
#			part_0 + '\t' +
#			part_4.encode('utf-8') + '\t' +
#			part_1 + '\t' +
#			part_2 + '\t' +
#			part_3.encode('utf-8') + '\n'
#		)

#	if '100' in record:
#		print(IDENT + '||' + record['100'].value())

	#if record.leader[7] == 'b':
	#	for F in metadata.get_fields('773'):
	#		if 't' in F and 'x' in F:
	#			if F['x'] == '0009-0468' and F['t'] == u'Česká literatura':
	#				BUFF+=str(IDENT) + chr(0x1F) + F.as_marc(encoding='utf-8') + '\n'
				#	print(F.as_marc(encoding='utf-8'))
					#for L in metadata.get_fields('856'):
					#	print(L.value().encode('utf-8'))
	# 600
 	#if len(metadata.get_fields('600')) == 1 and '7' not in metadata['600']:
	#	BIB=False
	#	for F in metadata.get_fields('655'):
	#		if 'a' in F and F['a'] in [
	#			u'biografické poznámky',
	 #			u'bio-bibliografické poznámky',
	#			u'biograficko-bibliografické poznámky',
	#			u'bibliografické poznámky',
	#			u'nekrology',
	#		 	u'medailony'
	#		]: BIB=True
	#	if BIB:
	#		six.write(str(IDENT) + '\n')

	# CLO
	#if metadata.leader[7] == 'b':
	#	if '100' in metadata and '700' not in metadata:
	#		for F in metadata.get_fields('773'):
	#			if '9' in F and 't' in F:
	#				if '245' in metadata and 'c' in metadata['245']:
	#					if '100' in metadata and 'a' in metadata['100']:
	#						clo.write(
	#							metadata['100']['a'].encode('utf-8') + '||' +
	#							metadata['245']['c'].encode('utf-8') + '||' +
	#							F['9'][:4].encode('utf-8') + '||' +
	#							F['t'].encode('utf-8') + '||' +
	#							F.value().encode('utf-8') + '||' +
	#							str(IDENT) + '\n'
	#						)

	#if IDENT > 
	#	print("Time.")
	#sys.exit(1)
			
	#	VAL = re.sub('( +,| +;| +:)$','', VAL).strip().strip('[').strip(']')
	#	csv_260a.write(str(IDENT) + ';' + VAL.encode('utf-8') + '\n')
	#	for VAL in F.get_subfields('z'):
	#		VAL = re.sub('( ?,| ?;| ?:)$','', VAL).strip().strip('[').strip(']')
	#		csv_260b.write(str(IDENT) + ';' + VAL.encode('utf-8') + '\n')
	#	for F in metadata.get_fields('264'):
	#		for VAL in F.get_subfields('a'):
	#			VAL = re.sub('( +,| +;| +:)$','', VAL).strip().strip('[').strip(']')
	#			csv_264a.write(str(IDENT) + ';' + VAL.encode('utf-8') + '\n')
	#	for VAL in F.get_subfields('b'):
	#		VAL = re.sub('( ?,| ?;| ?:)$','', VAL).strip().strip('[').strip(']')
	#		csv_264b.write(str(IDENT) + ';' + VAL.encode('utf-8') + '\n')

	#	if 'SIF' in metadata:
	#		if 'a' in metadata['SIF']: SIF = metadata['SIF']['a'].encode('utf-8')
	#	else:
	#		SIF = ''

	#	if metadata.leader[7]  == 'b':

# ------------------------------------------------------
# Webarchiv
# ------------------------------------------------------

	# GET DATA

	# drop idnes.cz, ihned.cz, webarchiv.cz, email.seznam.cz

#	IDENT = metadata['001'].value()
	
#	INT=False
#	for F in metadata.get_fields('964'):
#		if F.value() == 'INT': INT=True
#	if INT:
#		ARCH=False
#		for F in metadata.get_fields('856'):
#			if F['y'] in ['WebArchiv', 'Webarchiv']: ARCH=True
#		if not ARCH:
#			for F in metadata.get_fields('856'):
#				if F['y']  == 'online':
#					link.write(str(IDENT) + '##' + F['u'].encode('utf-8') + '\n')
#
#	return

# GET LINK

#session = requests.Session()

#session.headers.update({'User-Agent' : 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:70.0) Gecko/20100101 Firefox/70.0'})

#for LINK in link:

#	ID=LINK.split('##')[0].strip()
#	BASE=LINK.split('##')[1].replace('http://', '').replace('https://', '').strip()
#	URL='https://wayback.webarchiv.cz/wayback/*/' + BASE

	#try:
	#	req = session.get(URL)
	#except Exception as e:
	#	print(e.args)
	#	sys.exit(1)

#	req = session.get(URL, verify=False)

#	if req and req.status_code == 200:
#		try:
#			p = lxml.html.HTMLParser()
#			t = lxml.html.parse(StringIO.StringIO(req.text), p)
#			url = t.xpath(".//div[@id='wbMeta']//p[@class='wbThis']//a")

#			wayback.write(str(ID) + '##' + BASE + '##' + url[1].get('href').encode('utf-8') + '\n')
#		except:
#			pass

#	continue	

	# WRITE ALEPH

#	IDENT = metadata['001'].value()

#	if IDENT in WAY:
#		print(IDENT)
#		for F in metadata.get_fields('856'):
		
#			SUB=''
#			for i in range(0, len(F.subfields)/2):
#				SUB+='$$' + F.subfields[i*2] + F.subfields[i*2+1]

#			if F['u'] == 'https://' + WAY[IDENT]['ORIG'] or F['u'] == 'http://' + WAY[IDENT]['ORIG']:
#				aleph.write(str(IDENT + ' 856' + F.indicator1 + F.indicator2 + ' L ') + SUB.encode('utf-8') + '\n')
#				aleph.write(str(IDENT + ' 85642 L $$u') + WAY[IDENT]['ARCH'].encode('utf-8') + '$$yWebarchiv$$4N\n')
#			else:
#				aleph.write(str(IDENT + ' 856' + F.indicator1 + F.indicator2 + ' L ') + SUB.encode('utf-8') + '\n')
#	return

# ------------------------------------------------------
# 773 / 787
# ------------------------------------------------------

#	IDENT = metadata['001'].value()

#	if 'SIF' in metadata:
#		if 'a' in metadata['SIF']: SIF = metadata['SIF']['a'].encode('utf-8')
#	else:
#		SIF = ''

	# DATA
#	for F in metadata.get_fields('773'):
#		SUBS=''
#		for S in ['a', 't', 'x', 'n', 'd', 'b', 'k', 'y', 'g', 'q', '9', 'z']:
#			SUBS += '|' + '@'.join(F.get_subfields(S))

#		csv_773.write(
#			str(IDENT) + '|' +
#			SIF + '|' +
#			str(record.leader[7]) + '|' +
#			'https://vufind.ucl.cas.cz/Record/' + str(IDENT).ljust(9, '0') + '|' + # zero padding
#			F.value().encode('utf-8') +
#			SUBS.encode('utf-8') + 
#			'\n'
#		)
	
	# DATA
#	for F in metadata.get_fields('787'):
#		SUBS=''
#		for S in ['i', 'a', 't', 'n', 'd', 'b', 'k', 'h', 'z', 'y', '4', 'x']:
#			SUBS += '|' + '@'.join(F.get_subfields(S))

#		csv_787.write(
#			str(IDENT) + '|' +
#			SIF + '|' +
#			str(record.leader[7]) + '|' +
#			'https://vufind.ucl.cas.cz/Record/' + str(IDENT).ljust(9, '0') + '|' + # zero padding
#			F.value().encode('utf-8') +
#			SUBS.encode('utf-8') +
#			'\n'
#		)

# ------------------------------------------------------
# 505 '[]$' g -> t[./]? + split
# ------------------------------------------------------

	IDENT = metadata['001'].value()
	
#	MATCH = False	

	if record.leader[7] == 'm':
		for F in metadata.get_fields('505'):
			if len(F.get_subfields('t')) != 1:
#				print(IDENT + '# T')
				continue
			if len(F.get_subfields('g')) != 1:
#				print(IDENT + '# G')
				continue	

			BRACE = re.findall('(\[[^\[\]]+\])$', F['g'])

			if BRACE and re.match('.*\d+.*', BRACE[0]):
#				print(IDENT + '# NUM')
				continue	
			if re.match('.*\[.+\] --$', F['g']):
#				print(IDENT + '# --')
				continue	
			if BRACE:				
				MATCH = True
				BEFORE = F.value()
				if re.match('^\[.+\]$', F['g']):
					F.delete_subfield('g')
					F['t'] = F['t'].replace(' /', ' ' + BRACE[0] + ' /').strip()
				elif 'r' in F:
					F['g'] = F['g'].replace(BRACE[0], '').strip()
					F['t'] = F['t'].replace(' /', ' ' + BRACE[0] + ' /').strip()
				else:
					F['g'] = F['g'].replace(BRACE[0], '').strip()
					F['t'] = F['t'].replace(' ,', ' ' + BRACE[0] + ' ,').strip()

#				print(IDENT + '# MATCH')
#			if MATCH:
#				file0.write(str(IDENT + ';') + BEFORE.encode('utf-8') + str(';') + F.value().encode('utf-8') + '\n')
		# write changed record
#		if MATCH:
#			for F in metadata.get_fields('505'):
#				SUB=''
#				for i in range(0, len(F.subfields)/2):
#					SUB+='$$' + F.subfields[i*2] + F.subfields[i*2+1]
#				aleph.write(str(IDENT + ' 505' + F.indicator1 + F.indicator2 + ' L ') + SUB.encode('utf-8') + '\n')

#	IDENT = metadata['001'].value()

#	if IDENT == '001309536':
#		print(metadata)
#		sys.exit(0)

	if metadata.leader[7] == 'm':
		if len(metadata.get_fields('505')) > 1:
			for F in metadata.get_fields('505'):
			
				record = Record()
				# FMT
				record.add_field(Field(tag = 'FMT', data='AN'))
				# LDR
				record.leader = '     naa a22     4i 4500'
				#
				# 001 - KnAV
				record.add_field(Field(tag = '001', data='sb' + str(INDEX).zfill(6)))
				# 003
				record.add_field(Field(tag = '003', data='CZ PrUCL'))
				# 008
				DATA = '210705'#KnAV
				YEAR='xXXXX'
				if '260' in metadata:
					if 'c' in metadata['260'] and re.match('^\d{4}\.?$', metadata['260']['c']):
						YEAR= 's' + metadata['260']['c'].strip('.')
				if '264' in metadata:
					if 'c' in metadata['264'] and re.match('^\d{4}\.?$', metadata['264']['c']):
						YEAR= 's' + metadata['264']['c'].strip('.')
				DATA += YEAR + '    '
				LANG='xxx'
				if '041' in metadata and len(metadata['041'].get_subfields('a')) <= 1:
					LANG=metadata['008'].value()[15:18]
				if '041' not in metadata: LANG=metadata['008'].value()[15:18]
				COUNTRY='xxx'
				if '044' in metadata and len(metadata['044'].get_subfields('a')) == 0:
					COUNTRY=metadata['008'].value()[35:38]
				if '044' not in metadata: COUNTRY=metadata['008'].value()[35:38]
				DATA += LANG + '           ||| ||' + COUNTRY + ' d'
				record.add_field(Field(tag = '008', data=DATA))
				# 040
				record.add_field(Field(tag = '040', indicators = [' ', ' '], subfields = ['a', 'ABB060', 'b', 'cze', 'e', 'rda']))
				# 100
				DATA=''
				if 'r' in F:
					if not ',' in F['r'].strip(','):
						NAME=F['r'].strip(',').split(' ')
						MATCH=False
						for AUT in metadata.get_fields('700'):
							for PART in NAME:
								if PART in AUT.value():
									MATCH=True
								else:
									 MATCH=False
							if MATCH:
								DATA = AUT.subfields
								record.add_field(Field(tag = '100', indicators = ['1', ' '], subfields = DATA))
								break
						if not MATCH:
							NAME.insert(0, NAME.pop())
							NAME[0] = NAME[0] + ','
							record.add_field(Field(tag = '100', indicators = ['1', ' '], subfields = ['a', ' '.join(NAME)]))
				else:
					if '100' in metadata:
						record.add_field(Field(tag = '100', indicators = ['1', ' '], subfields = metadata['100'].subfields))
				if '100' in record:# insert 'aut'
					pos=None
					while '4' in record['100']: record['100'].delete_subfield('4')
					if '7' in record['100']: pos = record['100'].subfields.index('7')/2
					record['100'].add_subfield('4', u'aut', pos)
				# 245
				DATA=[]
				A,B,C='','',''
				if 't' in F:
					# A
					if ':' in F['t']:
						A = re.sub('((?<!:)):.+','\\1', F['t']).strip()
					elif re.match('^\[.*\.\.\.\]$', F['t'].strip('/ ')):
						A = re.sub('^\[(.*)\.\.\.\]$', '\\1', F['t']).strip('/ ')
					else:
						A = re.sub('(.*)\[.*', '\\1', F['t'].strip()).strip('/ ')
					if A: DATA += ['a', A]
					# B
					if re.match('.*:(.*)\[.*', F['t'].strip()): B = re.sub('.*:(.*)\[.*','\\1', F['t']).strip()
					if B: DATA += ['b', B]
				if 'r' in F:
					# C
					C = F['r'].strip(', ')
				elif '245' in metadata and 'c' in metadata['245']:
					C = re.sub('^([^;]+).*', '\\1', metadata['245']['c'])
				if C and not re.match('.*\.$', C): C = C.strip() + '.'# append dot
				for S in re.findall(' ?\( ?s\. ?.+?\) ?', C):# non-greedy page removal
					C = C.replace(S, ' ')
				if C: DATA += ['c', C]
				if len(DATA) == 4:
					if 'c' in DATA:
						DATA[1] = DATA[1] + ' /'# insert /
					else:
						DATA[1] = DATA[1] + ' :'# insert :
				if len(DATA) == 6:
						DATA[1] = DATA[1] + ' :'# insert :
						DATA[3] = DATA[3] + ' /'# insert /
				if DATA: record.add_field(Field(tag = '245', indicators = ['1','0'], subfields = DATA))
				if not '100' in record and '245' in record: record['245'].indicator1 = '0'
				# 336
				record.add_field(Field(tag = '336', indicators = [' ', ' '], subfields = ['a', 'text', 'b', 'text', '2', 'rdacontent']))
				# 337
				record.add_field(Field(tag = '337', indicators = [' ', ' '], subfields = ['a', u'bez média', 'b', 'n', '2', 'rdamedia']))
				# 338
				record.add_field(Field(tag = '338', indicators = [' ', ' '], subfields = ['a', u'jiný', 'b', 'nz', '2', 'rdacarrier']))
				# 524
				PAGE=''
				if 'g' in F:
					if re.match('^([Ss]\. )?(\[?[0-9]+\]?|\[?[0-9]+\]?-\[?[0-9]+\]?)$', F['g'].strip()):
					 	PAGE = re.sub('^([Ss]\. )?(\[?[0-9]+\]?|\[?[0-9]+\]?-\[?[0-9]+\]?)$','\\2', F['g'].strip()).replace('[','').replace(']','')
				CITACE = citace(metadata, F, PAGE)
				if CITACE: record.add_field(CITACE)
				# 655
				if 't' in F:
					if not re.match('^\[.*\.\.\.\]$', F['t'].strip('/ ')):
						if re.match('.*\[(.+)\]', F['t']):
							record.add_field(Field(tag = '655', indicators = [' ', ' '], subfields = ['a', re.sub('.*\[(.+)\]', '\\1', F['t'].strip('/ '))]))
				# 773
				DATA=[]
				CNT,NAME=0,''
				if '100' in metadata and 'a' in metadata['100']:
					NAME += metadata['100']['a']
					CNT+=1
				for F in metadata.get_fields('700'):
					if '4' in F and F['4'] == 'aut':
						if not NAME:
							NAME = F['a'].strip(', ')
						else:
							NAME += u' – ' + F['a'].strip(', ')
						CNT+=1
						if CNT == 3:
							NAME += ' et al.'
							break
					else:
						break
				if NAME: DATA += ['a', NAME]
				if '245' in metadata and 'a' in metadata['245']:
					if 'b' in metadata['245']:
						DATA += ['t', metadata['245']['a'] + ' ' + metadata['245']['b'].strip('/ ')]
					else:
						DATA += ['t', metadata['245']['a'].strip('/ ')]
				if '245' in metadata and 'c' in metadata['245']:# remove (s. 14-68), add dot.
					if ';' not in metadata['245']['c'] and metadata['245']['c'][0].isupper():
						DATA += ['n', word_to_upper(metadata['245']['c'])]
					if len(re.findall(';', metadata['245']['c'])) == 1:
						DATA += ['n', re.sub('[^;]+;(.*)', '\\1', metadata['245']['c']).strip()]
					if len(re.findall(';', metadata['245']['c'])) == 2:
						DATA += ['n', re.sub('.*;(.*);.*', '\\1', metadata['245']['c']).strip()]
				if '264' in metadata:
					DATA += ['d', metadata['264'].value()]
				if '020' in metadata and 'a' in metadata['020']:
					DATA += ['z', metadata['020']['a']]
				if 'g' in F:
					DATA += ['g', F['g']]
				if '260' in metadata and 'c' in metadata['260']:
					DATA += ['9', metadata['260']['c']]
				if '264' in metadata and 'c' in metadata['264']:
					DATA += ['9', metadata['264']['c']]
				if DATA: record.add_field(Field(tag = '773', indicators = ['0', ' '], subfields = DATA))
				# 910
				record.add_field(Field(tag = '910', indicators = [' ', ' '], subfields = ['a', 'ABB060']))
				# 911
				record.add_field(Field(tag = '964', indicators = [' ', ' '], subfields = ['a', 'B12']))
				# LKR
				record.add_field(Field(tag = 'LKR', indicators = [' ', ' '], subfields = ['a', 'UP', 'b', metadata['001'].value(), 'c', 'KNA01']))
				# OWN
				record.add_field(Field(tag = 'OWN', indicators = [' ', ' '], subfields = ['a', 'UCLA']))
				# SIF
				record.add_field(Field(tag = 'SIF', indicators = [' ', ' '], subfields = ['a', 'SBOR']))
		
				# WRITE
				xml.write(record)
				# INDEX
				INDEX+=1

# ------------------------------------------------------
# 500 / 520
# ------------------------------------------------------

#	IDENT = metadata['001'].value()

#	for F in metadata.get_fields('500'):
#		if not re.match('.*[.?!]$', F.value()):
#			file0.write(str(IDENT + ';') + F.value().encode('utf-8') + '\n')
	
#	for F in metadata.get_fields('520'):
#		if not re.match('.*[.?!]$', F.value()):
#			file1.write(str(IDENT + ';') + F.value().encode('utf-8') + '\n')

# ------------------------------------------------------
# MAIN
# ------------------------------------------------------

#record = Record()

#record.leader = '     nam a22     4i 4500'
#field = Field(tag = '001', data='002524717')
#record.add_ordered_field(field)
#field = Field(tag = '015', indicators = [' ',' '], subfields = ['a', 'cnb000000000'])
#record.add_ordered_field(field)
#field = Field(tag = '100', indicators = [' ',' '], subfields = ['a', 'cnb<<foo>>00000000','b', u's<<b ubez média,oo>>fsdfsdfsdf <<foo>>','c','sdfsdfsdfsdf'])
#record.add_ordered_field(field)
#field = Field(tag = '100', indicators = [' ',' '], subfields = ['a', 'cnb000000000','b', u's<<>>fsdfsdfsdf <<foo>>','c','sdfsdfsdfsdf'])
#record.add_ordered_field(field)
#field = Field(tag = '245', indicators = [' ',' '], subfields = ['a', 'cnb000000000','c', u'ss<<b bez média,ar>>dfs; dfsdfsdf <<foo>>','d','sdfsdfsdfsdf'])
#record.add_ordered_field(field)

#validate(record)

marcxml.map_xml(validate, DATA)

#with open('x.csv','w') as edice:
#	edice.write(BUFF)
#with open('uclec.csv','w') as ucl:
#	ucl.write(BUFF)
#with = open('100.csv','w') as ucl:
#	ucl.write(BUFF_100)
#with = open('600.csv','w') as ucl:
#	ucl.write(BUFF_600)
#with open('700.csv','w') as ucl:
#	ucl.write(BUFF_700)

#csv_773.close()
#csv_787.close()

#link.close()
#wayback.close()
#aleph.close()

#xml.close()

#writer.close()
#writer1.close()
#writer2.close()
#writer3.close()
#writer4.close()

file0.close()
file1.close()
#file2.close()
#file3.close()
#file4.close()
#file5.close()
#file6.close()
#file7.close()
#file8.close()
#file9.close()
#file10.close()

#print('TOTAL 100:' + str(TOTAL_100))
#print('SEVEN 100:' + str(SEVEN_100))
#print('TOTAL 600:' + str(TOTAL_600))
#print('SEVEN 600:' + str(SEVEN_600))
#print('TOTAL 700:' + str(TOTAL_700))
#print('SEVEN 700:' + str(SEVEN_700))

#print(str(SIXTEEN))
#print(str(TOTAL))
#print(str(COUNTER))

# EXIT -------------------

sys.exit(0)

