#!/usr/bin/python
# -*- coding: utf-8 -*-

# INCLUDE -------------------

from __future__ import print_function

import StringIO,requests,lxml.html,time,sys,os,re

from pymarc import marcxml,Field,MARCWriter,MARCReader
from pymarc.record import Record

# VAR -------------------

#DATA='demo.xml'
#DATA='uclec.xml'
#DATA='uclo.xml'
DATA='ucla.xml'
#DATA='CLO964.mrc'

#TOTAL_100=0
#SEVEN_100=0
#TOTAL_600=0
#SEVEN_600=0
#TOTAL_700=0
#SEVEN_700=0

#BUFF=''

#SIXTEEN=0
#COUNTER=0

#csv_773 = open('773.csv', 'w')
#csv_773.write('IDENT|SIF|LDR|VUFIND|VALUE|a|t|x|n|d|b|k|y|g|q|9|z\n')

#csv_787 = open('787.csv', 'w')
#csv_787.write('IDENT|SIF|LDR|VUFIND|VALUE|i|a|t|n|d|b|k|h|z|y|4|x\n')
	
#file2 = open('600.csv', 'w')
#file3 = open('700.csv', 'w')

# WAYBACK ---------

#link = open('link.txt', 'r')
#wayback = open('wayback.csv', 'r')
#aleph = open('wayback.aleph', 'w')

#WAY={}
#for LINE in wayback:
#	ID=LINE.split('##')[0].strip()
#	ORIG=LINE.split('##')[1].strip()
#	ARCH=LINE.split('##')[2].strip()
	
#	if ID not in WAY: WAY[ID] = {}
#	WAY[ID]['ORIG']=ORIG
#	WAY[ID]['ARCH']=ARCH

# WAYBACK ---------

#writer = MARCWriter(open('uclec.mrc', 'wb'))

#writer1 = MARCWriter(open('clo964_1.mrc', 'wb'))
#writer2 = MARCWriter(open('clo964_2.mrc', 'wb'))
#writer3 = MARCWriter(open('clo964_3.mrc', 'wb'))
#writer4 = MARCWriter(open('clo964_4.mrc', 'wb'))

#DATADIR='/var/www/html/964'
#BASE=['B12', 'B45', 'B70', 'B80', 'B97', 'CLE', 'INT', 'RET', 'SMZ', 'PWC', 'MBK']

#reader = MARCReader(file(DATA))

def name_to_upper(s):
	if len(s.split(',')) == 2:
		return s.split(',')[0].strip().upper() + ', ' + s.split(',')[1].strip() 
	else:
		return s

#for record in reader:
def validate(record):

#	metadata = Record(force_utf8=True)
	metadata = record

# ------------------------------------------------------

#	global BUFF
#	global BUFF_100, BUFF_600, BUFF_700, TOTAL_100, SEVEN_100, TOTAL_600, SEVEN_600, TOTAL_700, SEVEN_700
#	global SIXTEEN
#	global COUNTER

	# LDR dup
#	metadata.remove_fields('LDR')# LDR dup

#	if metadata['001'].value() == '001232606': metadata.remove_fields('506')# UCLEC broken control field
#	if metadata['001'].value() == '001852470': return # UCLA skip broken encoding

	# UCLEC drop records [obsolate]
	#if metadata['001'].value() in ['001676249','002194963','002265478','001232724','002549375','001232855']: return
	#if metadata['001'].value() == '001232855': return

	# UCLEC: 912 -> 913 ind1 = 2
#	for F in [f for f in metadata.get_fields('912') if f.indicator1 == '2']: F.tag = '913'

	# UCLEC: 912 -> 911 ind1 = ' ' ind2 = ' '
#	for F in [f for f in metadata.get_fields('912') if f.indicator1 + f.indicator2 == '  ']: F.tag = '911'

	# UCLEC drop 506 fields
#	metadata.remove_fields('506')

#	print(metadata['001'].value())
	
	#if int(metadata['001'].value()) > 35900:	
	#	if int(metadata['001'].value()) % 50 == 0:
	#		raw_input("Press ENTER to continue...")

#	if int(metadata['001'].value()) > 36380 and int(metadata['001'].value()) < 36390:
#		print(record)
#		raw_input("Press ENTER to continue...")
#
#	COUNTER+=1

	# write MRC

#	if COUNTER > 1284:
#		writer4.write(metadata)
#		return		
#	if COUNTER > 856:
#		writer3.write(metadata)
#		return		
#	if COUNTER > 428:
#		writer2.write(metadata)
#		return		
#	writer1.write(metadata)

#	try:
#		IDENT = metadata['001'].value()
#	except:
#		print('Broken:')
#		print(metadata)

	# UCLA:  webarchiv
#	for F in metadata.get_fields('856'):
#		if 'y' in F:
#			if F['y'] == 'Weabrchiv': F['y'] = 'Webarchiv'
#			if F['y'] == 'WebArchiv': F['y'] = 'Webarchiv'
#			if F['y'] == 'Webarhciv': F['y'] = 'Webarchiv'
#			if F['y'] == 'Wenarchiv': F['y'] = 'Webarchiv'

	# UCLA: drop X
#	X=False
#	for F in metadata.get_fields('773'):
#		if X and 'x' in F: F.delete_subfield('x')# drop more than one
#		if 'x' in F: X = True# catch the first one

	# UCLA: add MBK
#	MBK=False
#	if '044' in metadata:
#		if 'a' in metadata['044']:
#			if metadata['044']['a'] != 'xr': MBK=True
#	if '008' in metadata:
#		if metadata['008'].value()[15:17] != 'xr': MBK=True
#	for F in metadata.get_fields('964'):
#		if 'CLE' in F.value(): MBK=False
#	if MBK:
#		metadata.add_ordered_field(Field(tag='964', indicators=[' ',' '], subfields=['a', 'MBK']))

	# 599 UCLO special
	#for F in metadata.get_fields('599'):
	#	if 'a' in F:
	#		BUFF+=F['a'] + str('|') + IDENT + '\n'

	# UCLO 599a
#	XEDICE=False
#	for F in metadata.get_fields('599'):
#		if 'a' in F and F['a'] == 'xedice':
#			XEDICE=True
#	if XEDICE:
#		COUNTER+=1
#		metadata.add_ordered_field(Field(tag='964', indicators=[' ',' '], subfields=['a', 'XEDICE']))
#		writer.write(metadata)

	# write MRC
	#writer.write(metadata)
#	print(metadata)

# ------------------------------------------------------
# BASE
# ------------------------------------------------------

#	if 'SIF' in metadata:
#		if 'a' in metadata['SIF']: SIF = metadata['SIF']['a'].encode('utf-8')
#	else:
#		SIF = ''

#	IDENT = metadata['001'].value()

#	if '964' and 'FMT' in metadata:# 990 -> FMT
#		for F in metadata.get_fields('964'):
#			base = F.value()
#			if base in BASE:
#				sub_base = metadata['FMT'].value()
#				try:
#					os.mkdir(DATADIR + '/'+ base)
#				except: pass
#				try:
#					os.mkdir(DATADIR + '/'+ base + '/' + sub_base)
#				except: pass
			
#				with open(DATADIR + '/'+ base + '/' + sub_base + '/' + base + '_' + sub_base + '.csv', 'a', 0) as f:
#					f.write(
#						str(IDENT) + ';' +
#						SIF + ';' +
#						str(record.leader[7]) + ';' +
#						'https://vufind.ucl.cas.cz/Record/' + str(IDENT).ljust(9, '0') + ';' +# zero padding
#						str(base) + '\n'
#					)

# ------------------------------------------------------
# GENERIC
# ------------------------------------------------------

	#if 'SIF' in metadata:
	#	if 'a' in metadata['SIF']: SIF = metadata['SIF']['a'].encode('utf-8')
	#else:
	#	SIF = ''

#	if '005' in metadata and '008' in metadata:
#		if int(metadata['005'].value()[:4]) >= 2016:
#			if int(metadata['005'].value()[:4]) > int(metadata['008'].value()[:4]):
#				SIXTEEN+=1
#			if int(metadata['005'].value()[:4]) == int(metadata['008'].value()[:4]):
#				if int(metadata['005'].value()[4:7]) > int(metadata['008'].value()[4:7]):
#					SIXTEEN+=1

#	if int(IDENT) >= int('002484593'):# 2020 only
#		for F in metadata.get_fields('100'):
#			TOTAL_100+=1
#			if '7' in F: SEVEN_100+=1
#			file1.write(str(IDENT) + str(';') + '$$'.join(F.subfields).encode('utf-8') + '\n')
#	
#		for F in metadata.get_fields('600'):
#			TOTAL_600+=1
#			if '7' in F: SEVEN_600+=1
#			file2.write(str(IDENT) + str(';') + '$$'.join(F.subfields).encode('utf-8') + '\n')
#
#		for F in metadata.get_fields('700'):
#			TOTAL_700+=1
#			if '7' in F: SEVEN_700+=1
#			file3.write(str(IDENT) + str(';') + '$$'.join(F.subfields).encode('utf-8') + '\n')

#	writer.write(rec)

	# 912
#	if '912' in metadata:
#		if '245' in metadata:
#			if 'a' in metadata['245']:
#				part_0 = metadata['245']['a'].encode('utf-8')
#			else:
#				part_0 = ''
#			part_1 = '$$'.join(metadata['245'].subfields).encode('utf-8') 
#		else:
#			part_1 = ''
#
#		if '246' in metadata:
#			part_2 = '$$'.join(metadata['246'].subfields).encode('utf-8') 
#		else:
#			part_2 = ''
#
#		ALL1 = [ F['r'] for F in metadata.get_fields('912') if F.indicator1 == ' ' and F.indicator2 == ' ' and 'r' in F]
#		if len(ALL1) == 1:
#			part_3 = ALL1[0]
#		elif len(ALL1) > 1:
#			part_3 = '#'.join(ALL1)
#		else:
#			part_3 = ''
#
#		ALL2 = [ F['r'] for F in metadata.get_fields('912') if F.indicator1 == '2' and 'r' in F]
#		if len(ALL2) == 1:
#			part_4 = ALL2[0]
#		elif len(ALL2) > 1:
#			part_4 = ALL2[0] + '#' + ALL2[-1]
#		else:
#			part_4 = ''

#		BUFF+=(
#			str(IDENT) + '\t' +
#			part_0 + '\t' +
#			part_4.encode('utf-8') + '\t' +
#			part_1 + '\t' +
#			part_2 + '\t' +
#			part_3.encode('utf-8') + '\n'
#		)

#	if '100' in record:
#		print(IDENT + '||' + record['100'].value())

	#if record.leader[7] == 'b':
	#	for F in metadata.get_fields('773'):
	#		if 't' in F and 'x' in F:
	#			if F['x'] == '0009-0468' and F['t'] == u'Česká literatura':
	#				BUFF+=str(IDENT) + chr(0x1F) + F.as_marc(encoding='utf-8') + '\n'
				#	print(F.as_marc(encoding='utf-8'))
					#for L in metadata.get_fields('856'):
					#	print(L.value().encode('utf-8'))
	# 600
 	#if len(metadata.get_fields('600')) == 1 and '7' not in metadata['600']:
	#	BIB=False
	#	for F in metadata.get_fields('655'):
	#		if 'a' in F and F['a'] in [
	#			u'biografické poznámky',
	 #			u'bio-bibliografické poznámky',
	#			u'biograficko-bibliografické poznámky',
	#			u'bibliografické poznámky',
	#			u'nekrology',
	#		 	u'medailony'
	#		]: BIB=True
	#	if BIB:
	#		six.write(str(IDENT) + '\n')

	# CLO
	#if metadata.leader[7] == 'b':
	#	if '100' in metadata and '700' not in metadata:
	#		for F in metadata.get_fields('773'):
	#			if '9' in F and 't' in F:
	#				if '245' in metadata and 'c' in metadata['245']:
	#					if '100' in metadata and 'a' in metadata['100']:
	#						clo.write(
	#							metadata['100']['a'].encode('utf-8') + '||' +
	#							metadata['245']['c'].encode('utf-8') + '||' +
	#							F['9'][:4].encode('utf-8') + '||' +
	#							F['t'].encode('utf-8') + '||' +
	#							F.value().encode('utf-8') + '||' +
	#							str(IDENT) + '\n'
	#						)

	#if IDENT > 
	#	print("Time.")
	#sys.exit(1)
			
	#	VAL = re.sub('( +,| +;| +:)$','', VAL).strip().strip('[').strip(']')
	#	csv_260a.write(str(IDENT) + ';' + VAL.encode('utf-8') + '\n')
	#	for VAL in F.get_subfields('z'):
	#		VAL = re.sub('( ?,| ?;| ?:)$','', VAL).strip().strip('[').strip(']')
	#		csv_260b.write(str(IDENT) + ';' + VAL.encode('utf-8') + '\n')
	#	for F in metadata.get_fields('264'):
	#		for VAL in F.get_subfields('a'):
	#			VAL = re.sub('( +,| +;| +:)$','', VAL).strip().strip('[').strip(']')
	#			csv_264a.write(str(IDENT) + ';' + VAL.encode('utf-8') + '\n')
	#	for VAL in F.get_subfields('b'):
	#		VAL = re.sub('( ?,| ?;| ?:)$','', VAL).strip().strip('[').strip(']')
	#		csv_264b.write(str(IDENT) + ';' + VAL.encode('utf-8') + '\n')

	#	if 'SIF' in metadata:
	#		if 'a' in metadata['SIF']: SIF = metadata['SIF']['a'].encode('utf-8')
	#	else:
	#		SIF = ''

	#	if metadata.leader[7]  == 'b':

# ------------------------------------------------------
# Webarchiv
# ------------------------------------------------------

	# GET DATA

	# drop idnes.cz, ihned.cz, webarchiv.cz, email.seznam.cz

#	IDENT = metadata['001'].value()
	
#	INT=False
#	for F in metadata.get_fields('964'):
#		if F.value() == 'INT': INT=True
#	if INT:
#		ARCH=False
#		for F in metadata.get_fields('856'):
#			if F['y'] in ['WebArchiv', 'Webarchiv']: ARCH=True
#		if not ARCH:
#			for F in metadata.get_fields('856'):
#				if F['y']  == 'online':
#					link.write(str(IDENT) + '##' + F['u'].encode('utf-8') + '\n')

# GET LINK

#session = requests.Session()

#session.headers.update({'User-Agent' : 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:70.0) Gecko/20100101 Firefox/70.0'})

#for LINK in link:

#	ID=LINK.split('##')[0].strip()
#	BASE=LINK.split('##')[1].replace('http://', '').replace('https://', '').strip()
#	URL='https://wayback.webarchiv.cz/wayback/*/' + BASE
	
#	req = session.get(URL)

#	if req and req.status_code == 200:
#		try:
#			p = lxml.html.HTMLParser()
#			t = lxml.html.parse(StringIO.StringIO(req.text), p)
#			url = t.xpath(".//div[@id='wbMeta']//p[@class='wbThis']//a")

#			wayback.write(str(ID) + '##' + BASE + '##' + url[1].get('href').encode('utf-8') + '\n')
#		except:
#			pass

	# WRITE ALEPH

#	IDENT = metadata['001'].value()

#	if IDENT in WAY:
#		for F in metadata.get_fields('856'):
		
#			SUB=''
#			for i in range(0, len(F.subfields)/2):
#				SUB+='$$' + F.subfields[i*2] + F.subfields[i*2+1]

#			if F['u'] == 'https://' + WAY[IDENT]['ORIG'] or F['u'] == 'http://' + WAY[IDENT]['ORIG']:
#				aleph.write(str(IDENT) + ' 856' + F.indicator1 + F.indicator2 + ' L ' + SUB + '\n')
#				aleph.write(str(IDENT) + ' 85642 L $$u' + WAY[IDENT]['ARCH'] + '$$yWebarchiv$$4N\n')
#			else:
#				aleph.write(str(IDENT) + ' 856' + F.indicator1 + F.indicator2 + ' L ' + SUB + '\n')

# ------------------------------------------------------
# 773 / 787
# ------------------------------------------------------

#	IDENT = metadata['001'].value()

#	if 'SIF' in metadata:
#		if 'a' in metadata['SIF']: SIF = metadata['SIF']['a'].encode('utf-8')
#	else:
#		SIF = ''

	# DATA
#	for F in metadata.get_fields('773'):
#		SUBS=''
#		for S in ['a', 't', 'x', 'n', 'd', 'b', 'k', 'y', 'g', 'q', '9', 'z']:
#			SUBS += '|' + '@'.join(F.get_subfields(S))

#		csv_773.write(
#			str(IDENT) + '|' +
#			SIF + '|' +
#			str(record.leader[7]) + '|' +
#			'https://vufind.ucl.cas.cz/Record/' + str(IDENT).ljust(9, '0') + '|' + # zero padding
#			F.value().encode('utf-8') +
#			SUBS.encode('utf-8') + 
#			'\n'
#		)
	
	# DATA
#	for F in metadata.get_fields('787'):
#		SUBS=''
#		for S in ['i', 'a', 't', 'n', 'd', 'b', 'k', 'h', 'z', 'y', '4', 'x']:
#			SUBS += '|' + '@'.join(F.get_subfields(S))

#		csv_787.write(
#			str(IDENT) + '|' +
#			SIF + '|' +
#			str(record.leader[7]) + '|' +
#			'https://vufind.ucl.cas.cz/Record/' + str(IDENT).ljust(9, '0') + '|' + # zero padding
#			F.value().encode('utf-8') +
#			SUBS.encode('utf-8') +
#			'\n'
#		)

# ------------------------------------------------------
# CITACE
# ------------------------------------------------------

	IDENT = metadata['001'].value()
	
	# 100a – 700a: 245abnp. 245c. 773t. 773g.
	NAME,DATA,CTEXT,TTEXT,GTEXT = '','','','',''
	if metadata.leader[7] == 'b':
		# NAME
		if '100' in metadata:
			if len(metadata['100']['a'].rstrip(',').split(',')) == 2:
				NAME = name_to_upper(metadata['100']['a'].rstrip(',')) 
		for F in metadata.get_fields('700'):
			NAME += ' - ' + name_to_upper(F['a'].rstrip(','))
		# 245
		if '245' in metadata:
			# 245
			DATA = ': ' + ''.join([f.rstrip(' /') for f in metadata['245'].get_subfields('a','b','n','p')]) + '. '
			# 245c
			if 'c' in metadata['245']:
				if ';' in metadata['245']['c']:
					CTEXT =	re.sub('.*;(.*)', '\\1', metadata['245']['c']).capitalize().strip() + '. '
		# 773
		if '773' in metadata:
			# 773t (first..)
			if 't' in metadata['773']:
				TTEXT = metadata['773']['t'].strip() + '. '
			# 773g (first..)
			if 'g' in metadata['773']:
				GTEXT = metadata['773']['g'].rstrip('.').strip() + '.'
		print(NAME + DATA + CTEXT + TTEXT + GTEXT)

	#if metadata.leader[7] == 'a':
	#if metadata.leader[7] == 'm':

# ------------------------------------------------------
# MAIN
# ------------------------------------------------------

#record = Record()

#record.leader = '     nam a22     4i 4500'
#field = Field(tag = '001', data='002524717')
#record.add_ordered_field(field)
#field = Field(tag = '015', indicators = [' ',' '], subfields = ['a', 'cnb000000000'])
#record.add_ordered_field(field)

#validate(record)

marcxml.map_xml(validate, DATA)

#with open('x.csv','w') as edice:
#	edice.write(BUFF)
#with open('uclec.csv','w') as ucl:
#	ucl.write(BUFF)
#with = open('100.csv','w') as ucl:
#	ucl.write(BUFF_100)
#with = open('600.csv','w') as ucl:
#	ucl.write(BUFF_600)
#with open('700.csv','w') as ucl:
#	ucl.write(BUFF_700)

#csv_773.close()
#csv_787.close()

#link.close()
#wayback.close()
#aleph.close()

#writer1.close()
#writer2.close()
#writer3.close()
#writer4.close()

#file0.close()
#file1.close()
#file2.close()
#file3.close()

#print('TOTAL 100:' + str(TOTAL_100))
#print('SEVEN 100:' + str(SEVEN_100))
#print('TOTAL 600:' + str(TOTAL_600))
#print('SEVEN 600:' + str(SEVEN_600))
#print('TOTAL 700:' + str(TOTAL_700))
#print('SEVEN 700:' + str(SEVEN_700))

#print(str(SIXTEEN))
#print(str(COUNTER))

# EXIT -------------------

sys.exit(0)

